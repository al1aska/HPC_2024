{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yaf7k3rbCmpB",
        "outputId": "693294f0-2f83-4c21-bfae-e81a9069ef64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-4j_2f_zz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-4j_2f_zz\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnVKEEidCnfV",
        "outputId": "6847da20-bb3f-4c9b-dca2-c14e0254fa67"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your CUDA code to a file\n",
        "%%writefile hello_cuda.cu\n",
        "#include <iostream>\n",
        "__global__ void hello() {\n",
        "    printf(\"Hello from CUDA kernel!\\n\");\n",
        "}\n",
        "int main() {\n",
        "    hello<<<1, 10>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1tt8ipdCp39",
        "outputId": "ce3adec1-3571-4e12-8ac8-e264d0f4c351"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hello_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Компилируем код\n",
        "!nvcc hello_cuda.cu -o hello_cuda\n",
        "\n",
        "# Запускаем исполняемый файл\n",
        "!./hello_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXjTjwO4Cp1T",
        "outputId": "705c17a3-31c9-470d-b98c-cf2c84e232d4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from CUDA kernel!\n",
            "Hello from CUDA kernel!\n",
            "Hello from CUDA kernel!\n",
            "Hello from CUDA kernel!\n",
            "Hello from CUDA kernel!\n",
            "Hello from CUDA kernel!\n",
            "Hello from CUDA kernel!\n",
            "Hello from CUDA kernel!\n",
            "Hello from CUDA kernel!\n",
            "Hello from CUDA kernel!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kernel.cu\n",
        "#ifndef __CUDACC__\n",
        "    #define __CUDACC__\n",
        "#endif\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <string>\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <time.h>\n",
        "#include <malloc.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#define BLOCK_SIZE 512\n",
        "\n",
        "\n",
        "// функция подсчета суммы элементов вектора на cpu\n",
        "float sum_calculating_cpu(int* vec, int number_of_elements, int &sum);\n",
        "\n",
        "// функция подсчета суммы элементов вектора на gpu.\n",
        "__global__ void sum_calculating_gpu(int* vec, int* result, int number_of_elements);\n",
        "\n",
        "\n",
        "int main(int argc, char* argv[])\n",
        "{\n",
        "\tint summ_cpu = 0, summ_gpu = 0;\n",
        "\tsrand(time(NULL));\n",
        "\tint number_of_elements = 10000000;\n",
        "\tint to_bites = number_of_elements * sizeof(int);\n",
        "\n",
        "\t// выделение памяти на хосте\n",
        "\tint* vec = (int*)calloc(number_of_elements, sizeof(int));\n",
        "\tint* result_vect = (int*)calloc(number_of_elements, sizeof(int));\n",
        "\n",
        "\t// заполнение вектора рандомными числами\n",
        "\tfor (int i = 0; i < number_of_elements; ++i)\n",
        "\t{\n",
        "\t\tvec[i] = (int)rand() % 100;\n",
        "\t}\n",
        "\n",
        "\t// выделение памяти на гпу\n",
        "\tint* vec_on_device = NULL;\n",
        "\tcudaMalloc((void**)&vec_on_device, to_bites);\n",
        "\tint* result_vec_on_device= NULL;\n",
        "\tcudaMalloc((void**)&result_vec_on_device, to_bites);\n",
        "\n",
        "\t// создание обработчиков событий для отсчета времени\n",
        "\tcudaEvent_t start, stop;\n",
        "\tfloat time_on_gpu = 0.0f;\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEventCreate(&stop);\n",
        "\n",
        "\t// перенос данных на гпу\n",
        "\tcudaMemcpy(vec_on_device, vec, to_bites, cudaMemcpyHostToDevice);\n",
        "\n",
        "\t// начало события\n",
        "\tcudaEventRecord(start, 0);\n",
        "\n",
        "\t// выполнение подсчета суммы на гпу\n",
        "\tsum_calculating_gpu << < 1, BLOCK_SIZE >> > (vec_on_device, result_vec_on_device, number_of_elements);\n",
        "\n",
        "\t// перенос полученных данных обратно\n",
        "\tcudaMemcpy(result_vect, result_vec_on_device, to_bites, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\t// конец события\n",
        "\tcudaEventRecord(stop, 0);\n",
        "\t// синхронизация\n",
        "\tcudaEventSynchronize(stop);\n",
        "\t// подсчет времени между стартом события и его концом (по факту время вычисления суммы на гпу)\n",
        "\tcudaEventElapsedTime(&time_on_gpu, start, stop);\n",
        "\n",
        "\t// выполнение подсчета суммы на хосте\n",
        "\tfloat time_on_cpu = sum_calculating_cpu(vec, number_of_elements, summ_cpu);\n",
        "\tsumm_gpu = result_vect[0];\n",
        "\n",
        "\tstd::cout << \"\\nВремя подсчета суммы элементов вектора на GPU: \" << std::fixed << std::setprecision(2) << time_on_gpu << \" млс\\n\";\n",
        "\tstd::cout << \"\\nВремя подсчета суммы элементов вектора на CPU: \" << std::fixed << std::setprecision(2) << time_on_cpu << \" млс\\n\";\n",
        "\tstd::cout << \"\\nСумма CPU: \" << summ_cpu;\n",
        "\tstd::cout << \"\\nСумма GPU: \" << summ_gpu;\n",
        "\n",
        "\tcudaEventDestroy(start);\n",
        "\tcudaEventDestroy(stop);\n",
        "\tcudaFree(vec_on_device);\n",
        "\tcudaFree(result_vec_on_device);\n",
        "\tfree(vec);\n",
        "\tfree(result_vect);\n",
        "\n",
        "\treturn 0;\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void sum_calculating_gpu(int* vec, int* result, int number_of_elements)\n",
        "{\n",
        "\t// выделение общей памяти\n",
        "\t__shared__ int shared_array[BLOCK_SIZE];\n",
        "\tunsigned int threadId = threadIdx.x;\n",
        "\n",
        "\t// частичные суммы\n",
        "\tint partial = 0;\n",
        "\tfor (int i = threadId; i < number_of_elements; i += BLOCK_SIZE)\n",
        "\t{\n",
        "\t\tpartial += vec[i];\n",
        "\t}\n",
        "\n",
        "\tshared_array[threadId] = partial;\n",
        "\t__syncthreads();\n",
        "\n",
        "\tfor (unsigned int j = 1; j < blockDim.x; j *= 2)\n",
        "\t{\n",
        "\t\tif (threadId % (2 * j) == 0)\n",
        "\t\t{\n",
        "\t\t\tshared_array[threadId] += shared_array[threadId + j];\n",
        "\t\t}\n",
        "\t\t__syncthreads();\n",
        "\t}\n",
        "\n",
        "\tif (!threadId)\n",
        "\t{\n",
        "\t\tresult[blockIdx.x] += shared_array[0];\n",
        "\t}\n",
        "}\n",
        "\n",
        "float sum_calculating_cpu(int* vec, int number_of_elements, int &sum)\n",
        "{\n",
        "\tclock_t start = clock();\n",
        "\n",
        "\tfor (int i = 0; i < number_of_elements; i++)\n",
        "\t{\n",
        "\t\tsum += vec[i];\n",
        "\t}\n",
        "\n",
        "\tclock_t end = clock();\n",
        "\tfloat time = ((float)(end - start) / CLOCKS_PER_SEC) * 1000;\n",
        "\treturn time;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovcY7A-GCpyD",
        "outputId": "466b2cc6-3d64-4aa1-fbad-865b9f1b1ad5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Компилируем код\n",
        "!nvcc kernel.cu -o kernel\n",
        "\n",
        "# Запускаем исполняемый файл\n",
        "!./kernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XMseMm_Drp6",
        "outputId": "0302f910-bcac-4508-d4c4-20bb2da159f8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Время подсчета суммы элементов вектора на GPU: 36.76 млс\n",
            "\n",
            "Время подсчета суммы элементов вектора на CPU: 29.56 млс\n",
            "\n",
            "Сумма CPU: 495007044\n",
            "Сумма GPU: 495007044"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 000 - 0.23/0.01\n",
        "\n",
        "10 000 - 0.26/0.03\n",
        "\n",
        "50 000 - 0.36/0.13\n",
        "\n",
        "250 000 - 1.21/0.75\n",
        "\n",
        "1 000 000 - 3.74/2.83\n",
        "\n",
        "10 000 000 - 30.71/26.30"
      ],
      "metadata": {
        "id": "yRbtZlwSBmYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install altair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mkevZb3CAky",
        "outputId": "5815b2a8-d09d-471f-9781-c423b7132683"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: altair in /usr/local/lib/python3.10/dist-packages (4.2.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair) (4.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from altair) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.10/dist-packages (from altair) (2.2.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair) (0.12.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair) (0.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import altair as alt\n",
        "import pandas as pd\n",
        "\n",
        "# Данные\n",
        "data = {\n",
        "    'Size': [2_000, 10_000, 50_000, 250_000, 1_000_000, 10_000_000],\n",
        "    'CPU_Time': [0.01, 0.03, 0.13, 0.75, 2.83, 26.30],\n",
        "    'GPU_Time': [0.23, 0.26, 0.36, 1.21, 3.74, 30.71]\n",
        "}\n",
        "\n",
        "# Создание DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Расчет ускорения\n",
        "df['Speedup'] = df['CPU_Time'] / df['GPU_Time']\n",
        "\n",
        "# Построение графика\n",
        "chart = alt.Chart(df).mark_line(point=True).encode(\n",
        "    x=alt.X('Size:Q', title='Размерность вектора'),\n",
        "    y=alt.Y('Speedup:Q', title='Ускорение'),\n",
        "    tooltip=['Speedup:Q']\n",
        ").properties(\n",
        "    title='Ускорение работы программы на GPU относительно CPU'\n",
        ")\n",
        "\n",
        "# Отображение графика\n",
        "chart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "a3cWFLwwCC-1",
        "outputId": "05c178bb-b88d-40bd-e1bd-e137beb8821d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-04aba1a0225d4c69a334a4fbd937f0ff\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-04aba1a0225d4c69a334a4fbd937f0ff\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-04aba1a0225d4c69a334a4fbd937f0ff\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-7f60097e1850b5da3efb049e2a6bd5ec\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"tooltip\": [{\"field\": \"Speedup\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Size\", \"title\": \"\\u0420\\u0430\\u0437\\u043c\\u0435\\u0440\\u043d\\u043e\\u0441\\u0442\\u044c \\u0432\\u0435\\u043a\\u0442\\u043e\\u0440\\u0430\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Speedup\", \"title\": \"\\u0423\\u0441\\u043a\\u043e\\u0440\\u0435\\u043d\\u0438\\u0435\", \"type\": \"quantitative\"}}, \"title\": \"\\u0423\\u0441\\u043a\\u043e\\u0440\\u0435\\u043d\\u0438\\u0435 \\u0440\\u0430\\u0431\\u043e\\u0442\\u044b \\u043f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u044b \\u043d\\u0430 GPU \\u043e\\u0442\\u043d\\u043e\\u0441\\u0438\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e CPU\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-7f60097e1850b5da3efb049e2a6bd5ec\": [{\"Size\": 2000, \"CPU_Time\": 0.01, \"GPU_Time\": 0.23, \"Speedup\": 0.043478260869565216}, {\"Size\": 10000, \"CPU_Time\": 0.03, \"GPU_Time\": 0.26, \"Speedup\": 0.11538461538461538}, {\"Size\": 50000, \"CPU_Time\": 0.13, \"GPU_Time\": 0.36, \"Speedup\": 0.36111111111111116}, {\"Size\": 250000, \"CPU_Time\": 0.75, \"GPU_Time\": 1.21, \"Speedup\": 0.6198347107438017}, {\"Size\": 1000000, \"CPU_Time\": 2.83, \"GPU_Time\": 3.74, \"Speedup\": 0.7566844919786097}, {\"Size\": 10000000, \"CPU_Time\": 26.3, \"GPU_Time\": 30.71, \"Speedup\": 0.8563985672419407}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}